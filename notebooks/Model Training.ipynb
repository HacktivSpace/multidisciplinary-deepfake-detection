{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "This notebook handles the training of different models for the Multidisciplinary Deepfake Detection product. It includes steps for loading data, preprocessing, defining models, training, and saving the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import torch\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "# To set up logging\n",
    "logging.basicConfig(filename='../logs/model_training.log', level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# To load configuration\n",
    "from src.config import Config\n",
    "from src.dataset.data_loader import load_csv_data\n",
    "from src.dataset.data_splitter import split_data\n",
    "from src.models.cnn import CNNModel\n",
    "from src.models.transformer import TransformerModel\n",
    "from src.models.svm import SVMModel\n",
    "from src.models.bayesian import BayesianModel\n",
    "from src.models.vision_transformer import VisionTransformer\n",
    "from src.utils.logger import setup_logger\n",
    "\n",
    "logging.info(\"Model training started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To load Processed Data\n",
    "\n",
    "To load the processed data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load processed data\n",
    "processed_data_path = os.path.join(Config.PROCESSED_DATA_DIR, 'processed_data.csv')\n",
    "logging.info(\"Loading processed data from {}.\".format(processed_data_path))\n",
    "data = load_csv_data(processed_data_path)\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "logging.info(\"Processed data loaded successfully with shape {}.\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To split data\n",
    "\n",
    "To split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = split_data(X, y, test_size=0.2)\n",
    "logging.info(\"Data split into training and validation sets with training data shape: {} and validation data shape: {}.\".format(X_train.shape, X_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To train CNN Model\n",
    "\n",
    "To define, train, and save the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train CNN model\n",
    "logging.info(\"Training CNN model...\")\n",
    "cnn_model = CNNModel.build(input_shape=(64, 64, 3), num_classes=len(y.unique()))\n",
    "optimizer = Adam(learning_rate=Config.CNN_PARAMS['learning_rate'])\n",
    "\n",
    "cnn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_history = cnn_model.fit(X_train, y_train, epochs=Config.CNN_PARAMS['epochs'], batch_size=Config.CNN_PARAMS['batch_size'], validation_data=(X_val, y_val))\n",
    "\n",
    "# Save the trained model\n",
    "cnn_model_path = os.path.join(Config.MODEL_DIR, 'cnn_model.h5')\n",
    "cnn_model.save(cnn_model_path)\n",
    "logging.info(\"CNN model saved at {}\".format(cnn_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To train Transformer Model\n",
    "\n",
    "To define, train, and save the Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train Transformer model\n",
    "logging.info(\"Training Transformer model...\")\n",
    "transformer_model = TransformerModel(\n",
    "    input_dim=Config.TRANSFORMER_PARAMS['input_dim'],\n",
    "    model_dim=Config.TRANSFORMER_PARAMS['model_dim'],\n",
    "    num_heads=Config.TRANSFORMER_PARAMS['num_heads'],\n",
    "    num_layers=Config.TRANSFORMER_PARAMS['num_layers'],\n",
    "    output_dim=Config.TRANSFORMER_PARAMS['output_dim']\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=Config.TRANSFORMER_PARAMS['learning_rate'])\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(Config.TRANSFORMER_PARAMS['epochs']):\n",
    "    transformer_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = transformer_model(torch.tensor(X_train.values, dtype=torch.float32))\n",
    "    loss = criterion(outputs, torch.tensor(y_train.values, dtype=torch.float32))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    logging.info(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch + 1, Config.TRANSFORMER_PARAMS['epochs'], loss.item()))\n",
    "\n",
    "# To save the trained model\n",
    "transformer_model_path = os.path.join(Config.MODEL_DIR, 'transformer_model.pth')\n",
    "torch.save(transformer_model.state_dict(), transformer_model_path)\n",
    "logging.info(\"Transformer model saved at {}\".format(transformer_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM Model\n",
    "\n",
    "To define, train, and save the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train SVM model\n",
    "logging.info(\"Training SVM model...\")\n",
    "svm_model = SVMModel.build(kernel=Config.SVM_PARAMS['kernel'], C=Config.SVM_PARAMS['C'])\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# To save the trained model\n",
    "svm_model_path = os.path.join(Config.MODEL_DIR, 'svm_model.pkl')\n",
    "joblib.dump(svm_model, svm_model_path)\n",
    "logging.info(\"SVM model saved at {}\".format(svm_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To train Bayesian Model\n",
    "\n",
    "To define, train, and save the Bayesian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bayesian model\n",
    "logging.info(\"Training Bayesian model...\")\n",
    "bayesian_model = BayesianModel(prior_mean=Config.BAYESIAN_PARAMS['prior_mean'], prior_std=Config.BAYESIAN_PARAMS['prior_std'])\n",
    "bayesian_model.fit(X_train.values, y_train.values)\n",
    "\n",
    "# To save the trained model\n",
    "bayesian_model_path = os.path.join(Config.MODEL_DIR, 'bayesian_model.pkl')\n",
    "joblib.dump(bayesian_model, bayesian_model_path)\n",
    "logging.info(\"Bayesian model saved at {}\".format(bayesian_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To train Vision Transformer Model\n",
    "\n",
    "To define, train, and save the Vision Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train Vision Transformer model\n",
    "logging.info(\"Training Vision Transformer model...\")\n",
    "vision_transformer_model = VisionTransformer(\n",
    "    img_size=Config.VISION_TRANSFORMER_PARAMS['img_size'],\n",
    "    patch_size=Config.VISION_TRANSFORMER_PARAMS['patch_size'],\n",
    "    num_classes=Config.VISION_TRANSFORMER_PARAMS['num_classes'],\n",
    "    dim=Config.VISION_TRANSFORMER_PARAMS['dim'],\n",
    "    depth=Config.VISION_TRANSFORMER_PARAMS['depth'],\n",
    "    heads=Config.VISION_TRANSFORMER_PARAMS['heads'],\n",
    "    mlp_dim=Config.VISION_TRANSFORMER_PARAMS['mlp_dim']\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(vision_transformer_model.parameters(), lr=Config.VISION_TRANSFORMER_PARAMS['learning_rate'])\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(Config.VISION_TRANSFORMER_PARAMS['epochs']):\n",
    "    vision_transformer_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = vision_transformer_model(torch.tensor(X_train.values, dtype=torch.float32))\n",
    "    loss = criterion(outputs, torch.tensor(y_train.values, dtype=torch.float32))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    logging.info(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch + 1, Config.VISION_TRANSFORMER_PARAMS['epochs'], loss.item()))\n",
    "\n",
    "# Save the trained model\n",
    "vision_transformer_model_path = os.path.join(Config.MODEL_DIR, 'vision_transformer_model.pth')\n",
    "torch.save(vision_transformer_model.state_dict(), vision_transformer_model_path)\n",
    "logging.info(\"Vision Transformer model saved at {}\".format(vision_transformer_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The training of all models has been completed. The trained models have been saved to the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Model training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
